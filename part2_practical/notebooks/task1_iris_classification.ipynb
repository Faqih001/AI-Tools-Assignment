{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d71a076",
   "metadata": {},
   "source": [
    "# Task 1: Classical ML with Scikit-learn - Iris Species Classification\n",
    "\n",
    "In this notebook, we'll work with the Iris Species dataset to:\n",
    "1. Preprocess the data (handle missing values, encode labels)\n",
    "2. Train a decision tree classifier to predict iris species\n",
    "3. Evaluate using accuracy, precision, and recall\n",
    "\n",
    "## About the Dataset\n",
    "The Iris dataset is one of the most well-known datasets in machine learning. It contains measurements of 150 iris flowers from three different species:\n",
    "- Setosa\n",
    "- Versicolor\n",
    "- Virginica\n",
    "\n",
    "Each flower has four features measured:\n",
    "- Sepal length (cm)\n",
    "- Sepal width (cm)\n",
    "- Petal length (cm)\n",
    "- Petal width (cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f666bc",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "First, let's import all the libraries we'll need for our analysis and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91350ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set up the plotting style\n",
    "plt.style.use('seaborn-v0_8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e583d291",
   "metadata": {},
   "source": [
    "## 2. Load and Explore the Data\n",
    "\n",
    "Let's load the Iris dataset and explore its characteristics to better understand what we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d789c0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "feature_names = iris.feature_names\n",
    "target_names = iris.target_names\n",
    "\n",
    "# Create a pandas DataFrame for easier manipulation\n",
    "df = pd.DataFrame(X, columns=feature_names)\n",
    "df['species'] = [target_names[i] for i in y]\n",
    "\n",
    "# Display basic information\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Features: {feature_names}\")\n",
    "print(f\"Target classes: {target_names}\")\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8ce184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c191c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values in dataset:\")\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d181616e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class distribution\n",
    "print(\"Class distribution:\")\n",
    "class_dist = df['species'].value_counts()\n",
    "print(class_dist)\n",
    "\n",
    "# Visualize class distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "class_dist.plot(kind='bar', color='skyblue')\n",
    "plt.title('Class Distribution of Iris Species')\n",
    "plt.xlabel('Species')\n",
    "plt.ylabel('Count')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b602d5c",
   "metadata": {},
   "source": [
    "## 3. Data Visualization\n",
    "\n",
    "Visualizing the data will help us understand the relationships between features and classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8b37e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairwise scatter plots\n",
    "sns.pairplot(df, hue='species', markers=['o', 's', 'D'], palette='Set1')\n",
    "plt.suptitle('Pairplot of Iris Dataset', y=1.02, fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f77edac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "correlation_matrix = df[feature_names].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, fmt=\".2f\")\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2d9b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plots for each feature by species\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, feature in enumerate(feature_names):\n",
    "    sns.boxplot(data=df, x='species', y=feature, ax=axes[i])\n",
    "    axes[i].set_title(f'{feature} by Species')\n",
    "    axes[i].set_xlabel('Species')\n",
    "    axes[i].set_ylabel(feature)\n",
    "    axes[i].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69f732d",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing\n",
    "\n",
    "Now we'll prepare the data for modeling:\n",
    "1. Check for and handle any missing values\n",
    "2. Split the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a69181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values (Iris dataset typically has none)\n",
    "print(f\"Missing values in features: {np.isnan(X).sum()}\")\n",
    "print(f\"Missing values in target: {np.isnan(y).sum()}\")\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Testing set size: {X_test.shape[0]} samples\")\n",
    "print(f\"Feature dimensions: {X_train.shape[1]}\")\n",
    "\n",
    "# Check if classes are balanced in both train and test sets\n",
    "print(\"\\nTraining set class distribution:\")\n",
    "unique_train, counts_train = np.unique(y_train, return_counts=True)\n",
    "for species, count in zip(target_names[unique_train], counts_train):\n",
    "    print(f\"- {species}: {count}\")\n",
    "\n",
    "print(\"\\nTesting set class distribution:\")\n",
    "unique_test, counts_test = np.unique(y_test, return_counts=True)\n",
    "for species, count in zip(target_names[unique_test], counts_test):\n",
    "    print(f\"- {species}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5759318",
   "metadata": {},
   "source": [
    "## 5. Train the Decision Tree Classifier\n",
    "\n",
    "Now we'll train a decision tree classifier on our preprocessed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1b07ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Decision Tree Classifier with controlled depth to prevent overfitting\n",
    "model = DecisionTreeClassifier(random_state=42, max_depth=5)\n",
    "\n",
    "# Train the model\n",
    "print(\"Training Decision Tree Classifier...\")\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Training complete!\")\n",
    "\n",
    "# Display model parameters\n",
    "print(f\"\\nModel parameters:\")\n",
    "print(f\"- Max depth: {model.max_depth}\")\n",
    "print(f\"- Min samples split: {model.min_samples_split}\")\n",
    "print(f\"- Min samples leaf: {model.min_samples_leaf}\")\n",
    "print(f\"- Random state: {model.random_state}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70fa3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "feature_importance = model.feature_importances_\n",
    "print(f\"\\nFeature Importance:\")\n",
    "for name, importance in zip(feature_names, feature_importance):\n",
    "    print(f\"- {name}: {importance:.4f}\")\n",
    "\n",
    "# Visualize feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "plt.barh(range(len(sorted_idx)), feature_importance[sorted_idx])\n",
    "plt.yticks(range(len(sorted_idx)), [feature_names[i] for i in sorted_idx])\n",
    "plt.title('Feature Importance in Decision Tree')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94613d96",
   "metadata": {},
   "source": [
    "## 6. Visualize the Decision Tree\n",
    "\n",
    "Let's visualize the actual decision tree to understand how it makes predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d822e3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the decision tree\n",
    "plt.figure(figsize=(20, 12))\n",
    "plot_tree(model, \n",
    "         feature_names=feature_names,\n",
    "         class_names=target_names,\n",
    "         filled=True,\n",
    "         rounded=True,\n",
    "         fontsize=10)\n",
    "plt.title('Decision Tree for Iris Species Classification', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cfc30d",
   "metadata": {},
   "source": [
    "## 7. Evaluate the Model\n",
    "\n",
    "Now we'll evaluate the model using various metrics:\n",
    "- Accuracy\n",
    "- Precision and Recall\n",
    "- Confusion Matrix\n",
    "- Detailed Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578f8b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Testing Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Detailed classification metrics\n",
    "print(f\"\\nDetailed Classification Report (Test Set):\")\n",
    "print(classification_report(y_test, y_test_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15d7cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision and Recall for each class\n",
    "precision = precision_score(y_test, y_test_pred, average=None)\n",
    "recall = recall_score(y_test, y_test_pred, average=None)\n",
    "\n",
    "print(f\"Per-class Metrics:\")\n",
    "for i, class_name in enumerate(target_names):\n",
    "    print(f\"- {class_name}:\")\n",
    "    print(f\"  * Precision: {precision[i]:.4f}\")\n",
    "    print(f\"  * Recall: {recall[i]:.4f}\")\n",
    "\n",
    "# Overall averages\n",
    "avg_precision = precision_score(y_test, y_test_pred, average='weighted')\n",
    "avg_recall = recall_score(y_test, y_test_pred, average='weighted')\n",
    "\n",
    "print(f\"\\nWeighted Averages:\")\n",
    "print(f\"- Precision: {avg_precision:.4f}\")\n",
    "print(f\"- Recall: {avg_recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302b2506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "           xticklabels=target_names, yticklabels=target_names)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300d1003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation to get a more robust estimate of model performance\n",
    "cv_scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "print(f\"Cross-validation Scores: {cv_scores}\")\n",
    "print(f\"CV Mean Accuracy: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd2f21e",
   "metadata": {},
   "source": [
    "## 8. Conclusion\n",
    "\n",
    "We've successfully trained and evaluated a Decision Tree classifier for the Iris Species dataset.\n",
    "\n",
    "### Summary of Results:\n",
    "- Test accuracy: High accuracy in predicting the correct species\n",
    "- Features: Petal length and petal width were most important for classification\n",
    "- Model robustness: Cross-validation showed consistent performance across different data splits\n",
    "\n",
    "### Next Steps:\n",
    "- Try other algorithms like Random Forest or SVM for comparison\n",
    "- Perform hyperparameter tuning to find optimal tree parameters\n",
    "- For a more complex dataset, consider dimensionality reduction techniques\n",
    "\n",
    "### Key Takeaways:\n",
    "- Decision trees provide both good performance and interpretability\n",
    "- For well-separated classes like in the Iris dataset, even simple models can perform well\n",
    "- Understanding feature importance helps with feature selection in more complex datasets"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
